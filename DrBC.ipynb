{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DrBC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1iykTh-oSPeVslapL_FKhTIdCYBKhhGyZ",
      "authorship_tag": "ABX9TyP8ba7bGmaNLSV5KvKhjKwq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erickuo5124/MLG_HW1/blob/main/DrBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n9LPJwby_sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90498ef-8604-4cc4-ce97-87eb4f6aaa6d"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.6MB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 10.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 23.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 19.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wmirh2h5zBfc",
        "outputId": "6c150520-880b-46aa-97a4-e82346c7af13"
      },
      "source": [
        "import glob\n",
        "\n",
        "ans_path = []\n",
        "data_path = []\n",
        "for filename in glob.glob('/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/*.txt'):\n",
        "  if 'score' in filename:\n",
        "    ans_path.append(filename)\n",
        "  else:\n",
        "    data_path.append(filename)\n",
        "\n",
        "print(data_path)\n",
        "print(ans_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/29.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/15.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/14.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/28.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/16.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/17.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/13.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/12.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/10.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/11.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/9.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/8.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/5.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/4.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/6.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/7.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/3.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/2.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/0.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/1.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/21.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/20.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/23.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/22.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/26.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/27.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/25.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/19.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/18.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/24.txt']\n",
            "['/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/29_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/3_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/11_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/24_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/5_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/22_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/8_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/17_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/28_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/2_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/10_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/25_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/4_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/9_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/23_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/16_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/1_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/26_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/13_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/18_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/7_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/15_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/20_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/0_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/27_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/12_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/19_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/6_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/14_score.txt', '/content/drive/MyDrive/MLG/hw1/hw1_data/Synthetic/5000/21_score.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Y7GXg7zRbu"
      },
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "from torch_geometric.data import Data, ClusterData, ClusterLoader\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "ans_group = []\n",
        "data_group = []\n",
        "loader_group = []\n",
        "\n",
        "for i in range(30):\n",
        "  ans = {}\n",
        "  with open(ans_path[i]) as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "      key, value = line.split()\n",
        "      key = eval(key)\n",
        "      ans[key] = eval(value)\n",
        "      line = f.readline()\n",
        "  ans_group.append(ans)\n",
        "\n",
        "  G = nx.read_edgelist(data_path[i], nodetype = int)\n",
        "  edge_index = from_networkx(G).edge_index\n",
        "  x = torch.tensor([[G.degree(node),1,1] for node in G.nodes], dtype=torch.float)\n",
        "  y = torch.tensor([ans[node] for node in G.nodes], dtype=torch.float)\n",
        "  data = Data(edge_index=edge_index, x=x, y=y)\n",
        "  data_group.append(data)\n",
        "  cluster_data = ClusterData(data, num_parts=128)\n",
        "  train_loader = ClusterLoader(cluster_data, batch_size=16, shuffle=True)\n",
        "  loader_group.append(train_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Z2JoQsOlT1"
      },
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "class GCNConv(MessagePassing):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(GCNConv, self).__init__(aggr='add')\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # Compute normalization.\n",
        "    row, col = edge_index\n",
        "    deg = degree(col, x.size(0), dtype=x.dtype) + 1\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "    # Start propagating messages.\n",
        "    return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "  def message(self, x_j, norm):\n",
        "    # Normalize node features.\n",
        "    return norm.view(-1, 1) * x_j"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anoI11ZlzULO"
      },
      "source": [
        "from torch.nn import Linear, GRUCell, ReLU\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential\n",
        "\n",
        "class DrBC(torch.nn.Module):\n",
        "  def __init__(self, num_L):\n",
        "    super(DrBC, self).__init__()\n",
        "    self.num_L = num_L\n",
        "\n",
        "    self.data_in = Sequential(Linear(data.num_features, 128), ReLU())\n",
        "    self.Aggregation = GCNConv(128, 128)\n",
        "    self.Combine = GRUCell(128, 128, bias=False)\n",
        "    self.data_out = Sequential(Linear(128, 64), ReLU(), Linear(64,1), ReLU())\n",
        "\n",
        "  def forward(self, graph):\n",
        "    # encoder\n",
        "    h = self.data_in(graph.x.cuda())\n",
        "    h = F.normalize(h,dim=-1,p=2)\n",
        "    layer = torch.tensor([]).cuda()\n",
        "    layer = torch.cat((layer, torch.unsqueeze(h, 0)))\n",
        "    for _ in range(self.num_L):\n",
        "      hn = self.Aggregation(h, graph.edge_index.cuda())\n",
        "      h_new = self.Combine(h, hn)\n",
        "      h_new = F.normalize(h,dim=-1,p=2)\n",
        "      layer = torch.cat((layer, torch.unsqueeze(h_new, 0)))\n",
        "\n",
        "    # h = F.normalize(h,dim=-1,p=2)\n",
        "    z, _ = torch.max(layer, 0)\n",
        "\n",
        "    # decoder\n",
        "    pred = self.data_out(z)\n",
        "    pred = torch.squeeze(pred)\n",
        "\n",
        "    # loss\n",
        "    label = graph.y.cuda()\n",
        "    edge_index = graph.edge_index.cuda()\n",
        "    pair_ids_src, pair_ids_tgt = edge_index[0], edge_index[1] # all pair smapling\n",
        "\n",
        "    preds = torch.index_select(pred, 0, pair_ids_src) - torch.index_select(pred, 0, pair_ids_tgt)\n",
        "    labels = torch.index_select(label, 0, pair_ids_src) - torch.index_select(label, 0, pair_ids_tgt)\n",
        "    preds, labels = torch.sigmoid(preds), torch.sigmoid(labels)\n",
        "    loss = torch.nn.BCELoss()(preds, labels)\n",
        "    return pred, loss"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6jdPcwOzXuy"
      },
      "source": [
        "def top_n_accuracy(train, n, ans):\n",
        "  num = int(len(train) * n/100)\n",
        "  train = train.tolist()\n",
        "  predict = {}\n",
        "  for i in range(len(train)):\n",
        "    predict[i] = train[i]\n",
        "\n",
        "  predict = sorted(predict.items(), key = lambda x: x[1], reverse = True)[:num]\n",
        "  ans = sorted(ans.items(), key = lambda x: x[1], reverse = True)[:num]\n",
        "  ans = [item[0] for item in ans]\n",
        "  hit = 0\n",
        "  for i in range(num):\n",
        "    if predict[i][0] in ans:\n",
        "      hit += 1\n",
        "  return hit/num"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ2B16EuCR4P"
      },
      "source": [
        "def train(i):\n",
        "  model.train()\n",
        "\n",
        "  for sub_data in loader_group[i]:\n",
        "    optimizer.zero_grad()\n",
        "    out, loss = model(sub_data)\n",
        "    # print(out)\n",
        "    # print(f'Epoch: {epoch:03d}, G_index: {index:02d}, Loss: {loss:.6f}, Accuracy: {top_n_accuracy(out, 10, ans_group[index])}')\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hkzV2D2HzZRZ",
        "outputId": "ffb3e514-cc19-47ce-b6db-dd6979d559db"
      },
      "source": [
        "from IPython.display import Javascript  # Restrict height of output cell.\n",
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "model = DrBC(5).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "index = 0\n",
        "for epoch in range(10000):\n",
        "  # train(index)\n",
        "  out, loss = model(data_group[index])\n",
        "  # print(out)\n",
        "  print(f'Epoch: {epoch:03d}, G_index: {index:02d}, Loss: {loss:.6f}, Accuracy: {top_n_accuracy(out, 10, ans_group[index])}')\n",
        "  index += 1 if index < 29 else -29"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 000, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 001, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 002, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 003, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 004, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 005, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 006, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 007, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 008, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 009, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 010, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 011, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 012, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 013, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 014, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 015, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 016, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 017, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 018, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 019, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 020, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 021, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 022, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 023, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 024, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 025, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 026, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 027, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 028, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 029, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 030, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 031, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 032, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 033, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 034, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 035, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 036, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 037, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 038, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 039, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 040, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 041, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 042, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 043, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 044, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 045, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 046, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 047, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 048, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 049, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 050, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 051, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 052, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 053, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 054, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 055, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 056, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 057, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 058, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 059, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 060, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 061, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 062, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 063, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 064, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 065, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 066, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 067, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 068, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 069, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 070, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 071, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 072, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 073, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 074, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 075, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 076, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 077, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 078, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 079, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 080, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 081, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 082, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 083, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 084, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 085, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 086, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 087, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 088, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 089, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 090, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 091, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 092, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 093, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 094, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 095, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 096, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 097, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 098, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 099, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 100, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 101, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 102, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 103, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 104, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 105, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 106, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 107, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 108, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 109, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 110, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 111, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 112, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 113, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 114, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 115, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 116, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 117, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 118, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 119, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 120, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 121, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 122, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 123, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 124, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 125, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 126, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 127, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 128, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 129, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 130, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 131, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 132, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 133, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 134, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 135, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 136, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 137, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 138, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 139, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 140, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 141, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 142, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 143, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 144, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 145, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 146, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 147, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 148, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 149, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 150, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 151, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 152, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 153, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 154, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 155, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 156, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 157, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 158, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 159, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 160, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 161, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 162, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 163, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 164, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 165, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 166, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 167, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 168, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 169, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 170, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 171, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 172, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 173, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 174, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 175, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 176, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 177, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 178, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 179, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 180, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 181, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 182, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 183, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 184, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 185, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 186, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 187, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 188, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 189, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 190, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 191, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 192, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 193, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 194, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 195, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 196, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 197, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 198, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 199, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 200, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 201, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 202, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 203, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 204, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 205, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 206, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 207, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 208, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 209, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 210, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 211, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 212, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 213, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 214, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 215, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 216, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 217, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 218, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 219, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 220, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 221, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 222, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 223, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 224, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 225, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 226, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 227, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 228, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 229, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 230, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 231, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 232, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 233, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 234, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 235, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 236, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 237, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 238, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 239, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 240, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 241, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 242, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 243, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 244, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 245, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 246, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 247, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 248, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 249, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 250, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 251, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 252, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 253, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 254, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 255, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 256, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 257, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 258, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 259, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 260, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 261, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 262, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 263, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 264, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 265, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 266, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 267, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 268, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 269, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 270, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 271, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 272, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 273, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 274, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 275, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 276, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 277, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 278, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 279, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 280, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 281, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 282, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 283, G_index: 13, Loss: 0.693147, Accuracy: 0.73\n",
            "Epoch: 284, G_index: 14, Loss: 0.693147, Accuracy: 0.708\n",
            "Epoch: 285, G_index: 15, Loss: 0.693147, Accuracy: 0.732\n",
            "Epoch: 286, G_index: 16, Loss: 0.693147, Accuracy: 0.744\n",
            "Epoch: 287, G_index: 17, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 288, G_index: 18, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 289, G_index: 19, Loss: 0.693147, Accuracy: 0.728\n",
            "Epoch: 290, G_index: 20, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 291, G_index: 21, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 292, G_index: 22, Loss: 0.693147, Accuracy: 0.696\n",
            "Epoch: 293, G_index: 23, Loss: 0.693147, Accuracy: 0.692\n",
            "Epoch: 294, G_index: 24, Loss: 0.693147, Accuracy: 0.722\n",
            "Epoch: 295, G_index: 25, Loss: 0.693147, Accuracy: 0.72\n",
            "Epoch: 296, G_index: 26, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 297, G_index: 27, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 298, G_index: 28, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 299, G_index: 29, Loss: 0.693147, Accuracy: 0.716\n",
            "Epoch: 300, G_index: 00, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 301, G_index: 01, Loss: 0.693147, Accuracy: 0.706\n",
            "Epoch: 302, G_index: 02, Loss: 0.693147, Accuracy: 0.702\n",
            "Epoch: 303, G_index: 03, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 304, G_index: 04, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 305, G_index: 05, Loss: 0.693147, Accuracy: 0.71\n",
            "Epoch: 306, G_index: 06, Loss: 0.693147, Accuracy: 0.742\n",
            "Epoch: 307, G_index: 07, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 308, G_index: 08, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 309, G_index: 09, Loss: 0.693147, Accuracy: 0.718\n",
            "Epoch: 310, G_index: 10, Loss: 0.693147, Accuracy: 0.726\n",
            "Epoch: 311, G_index: 11, Loss: 0.693147, Accuracy: 0.712\n",
            "Epoch: 312, G_index: 12, Loss: 0.693147, Accuracy: 0.722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b78e15c5daa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# print(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch:03d}, G_index: {index:02d}, Loss: {loss:.6f}, Accuracy: {top_n_accuracy(out, 10, ans_group[index])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJLuQteyzm9A"
      },
      "source": [
        "torch.save(model, '/content/drive/MyDrive/MLG/hw1/net.pkl')\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/MLG/hw1/net_params.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7k4jIDN2y9g"
      },
      "source": [
        "test_path = '/content/drive/MyDrive/MLG/hw1/hw1_data/youtube/com-youtube.txt'\n",
        "testans_path = '/content/drive/MyDrive/MLG/hw1/hw1_data/youtube/com-youtube_score.txt'\n",
        "\n",
        "test_ans = {}\n",
        "with open(testans_path) as f:\n",
        "  line = f.readline()\n",
        "  while line:\n",
        "    key, value = line.split(':')\n",
        "    key = eval(key)\n",
        "    test_ans[key] = eval(value)\n",
        "    line = f.readline()\n",
        "\n",
        "G = nx.read_edgelist(test_path, nodetype = int)\n",
        "edge_index = from_networkx(G).edge_index\n",
        "x = torch.tensor([[G.degree(node),1,1] for node in G.nodes], dtype=torch.float)\n",
        "y = torch.tensor([test_ans[node] for node in G.nodes], dtype=torch.float)\n",
        "test_data = Data(edge_index=edge_index, x=x, y=y)\n",
        "test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ECgyAyW8KxW"
      },
      "source": [
        "out, loss = model(test_data)\n",
        "print(f'Loss: {loss:.6f}, Accuracy: {top_n_accuracy(out, 5, test_ans)}')\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1et6RUr8-oC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}